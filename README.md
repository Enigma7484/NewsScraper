# ğŸ“° News Scraper with Sentiment Analysis & Summarization

## ğŸ“Œ Overview
This project scrapes news articles from multiple sources, analyzes their sentiment, summarizes the content using an **LLM (T5 model)**, and stores the results in **MongoDB**.

### **ğŸ”¹ Features**
âœ… **Scrapes news from multiple websites**  
âœ… **Filters & categorizes articles** based on sentiment (Positive, Neutral, Negative) using Hugging Face's `siebert/sentiment-roberta-large-english`
âœ… **Uses an AI model for summarization** (Hugging Face's `t5-large`)  
âœ… **Stores articles in MongoDB for further analysis**  
âœ… **Easily extendable for new news sources**  

---

## âš¡ Setup Guide

### **1ï¸âƒ£ Install Dependencies**
Make sure you have Python installed (â‰¥ 3.13), then install required packages:
```bash
# Install uv if you don't have it yet
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies using uv
uv sync
```

### **2ï¸âƒ£ Setup MongoDB**
- Install [MongoDB](https://www.mongodb.com/try/download/community) and start it:
  ```bash
  mongod --dbpath /path/to/your/db
  ```
- If using **MongoDB Atlas (cloud)**, update the environment variables in `.env`:
  ```
  MONGO_URL=your-mongodb-connection-string
  DB_NAME=your-database-name
  COLLECTION_NAME=your-collection-name
  ```

### **3ï¸âƒ£ Setup Redis for Celery**
- If using Upstash Redis, add these to your `.env` file:
  ```
  UPSTASH_REDIS_URL=your-redis-url
  UPSTASH_REDIS_PASSWORD=your-redis-password
  ```

### **4ï¸âƒ£ Run the Scraper**
Scrape news headlines from all configured sources manually and then save them to the database:
```bash
python sentiment_analysis_pipeline.py  # Full pipeline with sentiment analysis
python save2db.py
```

### **5ï¸âƒ£ Run the API**
Start the Flask API to serve the results we got from manually running the above scripts:
```bash
python sentiment_api.py
```

---

## ğŸ“ Project Structure
```
ğŸ“‚ NewsScraper
â”œâ”€â”€ ğŸ“„ news_sites.json          # List of websites & their scraping configurations
â”œâ”€â”€ ğŸ“„ selector_scraper.py      # Scrapes headlines from news sources
â”œâ”€â”€ ğŸ“„ sentiment_analysis_pipeline.py  # Fetches articles, analyzes sentiment, summarizes content
â”œâ”€â”€ ğŸ“„ feed_data.py             # Handles sentiment analysis using RoBERTa model
â”œâ”€â”€ ğŸ“„ save2db.py               # Saves articles to MongoDB
â”œâ”€â”€ ğŸ“„ sentiment_api.py         # Flask API to serve sentiment analysis results
â”œâ”€â”€ ğŸ“„ celery_worker.py         # Celery worker for scheduled scraping
â”œâ”€â”€ ğŸ“„ pyproject.toml           # Project configuration and dependencies
â”œâ”€â”€ ğŸ“„ .env                     # Environment variables (MongoDB, Redis)
â”œâ”€â”€ ğŸ“„ README.md                # Setup guide & documentation
```

---

## ğŸ› ï¸ **Adding New Websites**
To add a new news source:
1. Open `news_sites.json`.
2. Add an entry following this format:
   ```json
   {
      "newsite": {
         "base_url": "https://www.example.com/news",
         "headline_xpath": "//h2[contains(@class, 'headline')]",
         "link_xpath": ".//ancestor::a/@href",
         "dynamic": false
      }
   }
   ```
3. Run `selector_scraper.py` to test.

---

## ğŸš€ Future Enhancements
- âœ… **Deploy sentiment analysis as an API**
- âœ… **Introduce real-time updates**
- âœ… **Enhance summarization with more advanced LLMs**
- âœ… **Create a web-based dashboard for visualization**

## Code Formatting

This project uses Black for code formatting. To format your code:

1. Install Black:
   ```bash
   pip install black
   ```

2. Format all Python files:
   ```bash
   black .
   ```

3. Format a specific file:
   ```bash
   black path/to/file.py
   ```

The project uses the following Black settings (defined in `.black`):
- Line length: 88 characters
- Target Python version: 3.7+
- String normalization: Single quotes
- Includes: Python files (`.py`, `.pyi`) and Markdown files (`.md`)

## Usage

1. Start the Flask API:
   ```bash
   python sentiment_api.py
   ```

2. Access the API endpoints:
   - GET `/articles` - List all articles
   - GET `/articles/<id>` - Get a specific article

## Project Structure

```
.
â”œâ”€â”€ sentiment_api.py      # Flask API server
â”œâ”€â”€ scraper.py           # News scraping module
â”œâ”€â”€ sentiment.py         # Sentiment analysis module
â”œâ”€â”€ summarizer.py        # Article summarization
â”œâ”€â”€ visualizer.py        # Sentiment visualization
â”œâ”€â”€ celery_worker.py     # Background task worker
â”œâ”€â”€ requirements.txt     # Project dependencies
â””â”€â”€ .env                 # Environment variables
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Format your code using Black
5. Submit a pull request

## License

MIT License
